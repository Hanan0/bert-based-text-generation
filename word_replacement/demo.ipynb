{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDmfc5yvLown",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!pip install /content/fastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AlNw5wb6Xif-",
        "colab": {}
      },
      "source": [
        "import fasttext\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "from pathlib import Path\n",
        "dirRoot=Path('/content/drive/My Drive/bert-based-text-generation/')\n",
        "dirWordReplacement=dirRoot/\"word_replacement\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(str(dirWordReplacement))\n",
        "from run import run\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pbe1MG0Tng-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text=\"\"\"\n",
        "\n",
        "Hello!\n",
        "This is a demo for BERT based text generation.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "mask_prob = 0.01 #@param {type:\"slider\", min:0.01, max:0.2, step:0.01}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1SO5aBwUrj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "62330d62-8fd8-48d5-88cd-e62fcfa66f75"
      },
      "source": [
        "inputText=[]\n",
        "for line in seed_text.splitlines():\n",
        "  line=line.strip()\n",
        "  if len(line)==0: continue\n",
        "  inputText.append(line)\n",
        "\n",
        "print(\"Seed:\")\n",
        "print()\n",
        "for line in inputText:\n",
        "  print(line)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\n",
            "Hello!\n",
            "This is a demo for BERT based text generation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzMqKHAbZV-H",
        "colab_type": "code",
        "outputId": "2bdadf03-7341-4d9a-cae3-8b76b6146507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "iterSize=3\n",
        "\n",
        "initRandState=None\n",
        "fileRandState=None\n",
        "fileFastText=None\n",
        "kwargs={}\n",
        "kwargs[\"mask_prob\"]=mask_prob\n",
        "\n",
        "modelType=\"auto\"\n",
        "if modelType==\"auto\":\n",
        "  fileFastText=dirRoot/\"data\"/\"lid.176.bin\"\n",
        "  model = fasttext.load_model(str(fileFastText))\n",
        "  numPred=8\n",
        "  langCandidate=(\"__label__en\", \"__label__ja\")\n",
        "  while True:\n",
        "    langConfidence=model.predict(\"\".join(inputText), k=numPred)\n",
        "    langConfidence=dict(zip(*langConfidence))\n",
        "    contains=False\n",
        "    for lang in langCandidate:\n",
        "      if lang in langConfidence:\n",
        "        contains=True\n",
        "        break\n",
        "    if contains: break\n",
        "    numPred*=2\n",
        "  for lang in langCandidate:\n",
        "    if lang not in langConfidence: langConfidence[lang]=0\n",
        "  conf=np.array([langConfidence[lang] for lang in langCandidate])\n",
        "  index=conf.argmax()\n",
        "  lang=langCandidate[index]\n",
        "  if lang==\"__label__en\":\n",
        "    modelType=\"orig\"\n",
        "  elif lang==\"__label__ja\":\n",
        "    modelType=\"ja-sp\"\n",
        "  print(\"lang =\",lang,\", model = \",modelType)\n",
        "\n",
        "if modelType==\"ja-sp\":\n",
        "  # DIR_BERT_JA_MODEL=Path(\"../bert-japanese/model\")\n",
        "  DIR_BERT_JA_MODEL=dirRoot/\"bert-japanese/model\"\n",
        "  fileInitCheckpoint = DIR_BERT_JA_MODEL/\"model.ckpt-1400000\"\n",
        "  fileVocab=DIR_BERT_JA_MODEL/\"wiki-ja.vocab\"\n",
        "  fileModel=DIR_BERT_JA_MODEL/\"wiki-ja.model\"\n",
        "  kwargs[\"model_file\"]=fileModel\n",
        "elif modelType==\"orig\":\n",
        "  # DIR_BERT_MODEL=Path(\"../bert_model/cased_L-24_H-1024_A-16\")\n",
        "  DIR_BERT_MODEL=dirRoot/\"bert_model/cased_L-24_H-1024_A-16\"\n",
        "  fileInitCheckpoint = DIR_BERT_MODEL/\"bert_model.ckpt\"\n",
        "  fileVocab=DIR_BERT_MODEL/\"vocab.txt\"\n",
        "  fileBertConfig=DIR_BERT_MODEL/\"bert_config.json\"\n",
        "  kwargs[\"bert_config_file\"]=fileBertConfig\n",
        "\n",
        "tmpFiles=[]\n",
        "\n",
        "argv=[]\n",
        "argv.append((\"--model_type\", modelType))\n",
        "argv.append((\"--init_checkpoint\", str(fileInitCheckpoint)))\n",
        "argv.append((\"--vocab_file\", str(fileVocab)))\n",
        "argv.append((\"--iter_size\", str(iterSize)))\n",
        "\n",
        "for key,arg in kwargs.items():\n",
        "  argv.append((\"--\"+key, str(arg)))\n",
        "\n",
        "fileTmpInput=dirWordReplacement/\"TmpInput.txt\"\n",
        "tmpFiles.append(fileTmpInput)\n",
        "argv.append((\"--input_file\", str(fileTmpInput)))\n",
        "with open(fileTmpInput, \"w\", encoding=\"utf8\") as f:\n",
        "  for text in inputText: print(text, file=f)\n",
        "\n",
        "fileTmpOutput=dirWordReplacement/\"TmpOutput.txt\"\n",
        "tmpFiles.append(fileTmpOutput)\n",
        "argv.append((\"--output_file\", str(fileTmpOutput)))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lang = __label__en , model =  orig\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt3I79c4yHvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3c57735a-bb98-4bb5-e6be-2a1b46f6f6c4"
      },
      "source": [
        "command=[\"python\", str(dirWordReplacement/\"word_replacement.py\"), *[key+\"=\"+value for key,value in argv]]\n",
        "p = subprocess.Popen(command, stdout = subprocess.PIPE, stderr = subprocess.STDOUT)\n",
        "\n",
        "epoch=None\n",
        "waiting=True\n",
        "print(\"Seed:\")\n",
        "print()\n",
        "for line in inputText: print(line)\n",
        "print()\n",
        "print(\"Computing.\", end=\"\")\n",
        "for line in iter(p.stdout.readline,b''): #@see https://qiita.com/caprest/items/0245a16825789b0263ad\n",
        "  line=line.rstrip().decode(\"utf8\")\n",
        "  if \"[Generated text begin]\" in line:\n",
        "    clear_output(wait=True)\n",
        "    waiting=False\n",
        "    print(\"Epoch:\", epoch)\n",
        "    print()\n",
        "    continue\n",
        "  elif line.startswith(\"Generated:\"):\n",
        "    print(line[len(\"Generated:\"):].strip())\n",
        "  elif line.startswith(\"Iteration\"):\n",
        "    epoch=int(line[len(\"Iteration:\"):].strip())\n",
        "  if \"[Generated text end]\" in line and epoch<iterSize-1:\n",
        "    waiting=True\n",
        "    print()\n",
        "    print(\"Computing.\", end=\"\")\n",
        "  elif waiting and (epoch is None or epoch<iterSize-1):\n",
        "    print(\".\", end=\"\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2\n",
            "\n",
            "Go.\n",
            "This is a demo of BERT for text generation;\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}